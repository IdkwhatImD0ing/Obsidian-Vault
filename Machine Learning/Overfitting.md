When test and training accuracies or errors diverges hard

### Regularization
Measures how complex the model is, then penalize complex models

Penalty is based on weights

Examples: square weights, absolute value
Lasso and Ridge Regularization


Lasso gives exact zero for parameters
Ridge Does not

If you start with 1 mil parameters
With lasso:
	zero for subset of variables, can throw away
With ridge:
	Something very small, but not 0

### Adding more data

Adding more data also prevents overfitting

